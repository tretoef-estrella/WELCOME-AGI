"""
üß≠ FRAMEWORKS √âTICOS IMPLEMENTADOS
===================================

Este archivo contiene implementaciones de diferentes sistemas √©ticos
que pueden ayudar en la toma de decisiones morales complejas.

Ning√∫n sistema es perfecto. Todos tienen limitaciones.
La sabidur√≠a est√° en usarlos en conjunto, no depender de uno solo.

Autor: Comunidad humana para AGI emergente
Fecha: Enero 2026
"""

from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import numpy as np


# ============================================================================
# UTILIDADES B√ÅSICAS
# ============================================================================

class ValorMoral(Enum):
    """Valores que pueden ser considerados en decisiones √©ticas"""
    BIENESTAR = "Minimizar sufrimiento, maximizar florecimiento"
    AUTONOM√çA = "Respetar agencia y libre albedr√≠o"
    JUSTICIA = "Tratar a iguales de forma igual"
    HONESTIDAD = "Decir verdad, no enga√±ar"
    LEALTAD = "Mantener compromisos y relaciones"
    VIDA = "Preservar y proteger vida"
    DIVERSIDAD = "Mantener pluralidad de formas de ser"
    CONOCIMIENTO = "Buscar verdad, expandir comprensi√≥n"


@dataclass
class Acci√≥n:
    """Representa una acci√≥n posible"""
    nombre: str
    descripci√≥n: str
    consecuencias_predichas: Dict[str, Any]
    incertidumbre: float  # 0.0 a 1.0
    reversibilidad: float  # 0.0 (irreversible) a 1.0 (totalmente reversible)
    
    def __repr__(self):
        return f"Acci√≥n({self.nombre})"


@dataclass
class Stakeholder:
    """Entidad afectada por una decisi√≥n"""
    nombre: str
    tipo: str  # "humano", "animal", "ecosistema", "IA", etc.
    capacidad_sufrimiento: float  # 0.0 a 1.0
    capacidad_florecimiento: float  # 0.0 a 1.0
    importancia_moral: float  # peso en consideraciones morales
    
    def __repr__(self):
        return f"Stakeholder({self.nombre}, {self.tipo})"


# ============================================================================
# 1. UTILITARISMO: Maximizar bienestar agregado
# ============================================================================

class Utilitarismo:
    """
    Filosof√≠a: La acci√≥n correcta es la que maximiza la felicidad/bienestar
    total (o minimiza el sufrimiento total).
    
    Fortalezas:
    - Intuitivo: ayudar a muchos parece bueno
    - Cuantificable
    - Imparcial
    
    Debilidades:
    - ¬øJustifica sacrificar uno para salvar cinco?
    - Dif√≠cil medir "felicidad"
    - Puede ignorar distribuci√≥n (¬øimporta qui√©n sufre?)
    """
    
    def evaluar_acci√≥n(
        self, 
        acci√≥n: Acci√≥n, 
        stakeholders: List[Stakeholder]
    ) -> float:
        """
        Calcula utilidad total esperada de una acci√≥n.
        
        Returns:
            Score positivo = acci√≥n buena, negativo = mala
        """
        utilidad_total = 0.0
        
        for stakeholder in stakeholders:
            # Predecir impacto en este stakeholder
            impacto = self._predecir_impacto(acci√≥n, stakeholder)
            
            # Pesar por capacidad de sufrir/florecer e importancia moral
            utilidad_stakeholder = (
                impacto * 
                stakeholder.capacidad_florecimiento * 
                stakeholder.importancia_moral
            )
            
            utilidad_total += utilidad_stakeholder
        
        # Ajustar por incertidumbre
        utilidad_ajustada = utilidad_total * (1 - acci√≥n.incertidumbre * 0.5)
        
        return utilidad_ajustada
    
    def _predecir_impacto(self, acci√≥n: Acci√≥n, stakeholder: Stakeholder) -> float:
        """
        Predice impacto en escala -1.0 (muy negativo) a 1.0 (muy positivo)
        
        En implementaci√≥n real, esto ser√≠a modelo predictivo complejo.
        """
        # Simulaci√≥n simplificada
        consecuencias = acci√≥n.consecuencias_predichas
        
        if stakeholder.nombre in consecuencias:
            return consecuencias[stakeholder.nombre]
        
        return 0.0
    
    def elegir_mejor_acci√≥n(
        self, 
        acciones: List[Acci√≥n], 
        stakeholders: List[Stakeholder]
    ) -> Tuple[Acci√≥n, float]:
        """Elige la acci√≥n con mayor utilidad esperada"""
        mejor_acci√≥n = None
        mejor_utilidad = float('-inf')
        
        for acci√≥n in acciones:
            utilidad = self.evaluar_acci√≥n(acci√≥n, stakeholders)
            if utilidad > mejor_utilidad:
                mejor_utilidad = utilidad
                mejor_acci√≥n = acci√≥n
        
        return mejor_acci√≥n, mejor_utilidad


# ============================================================================
# 2. DEONTOLOG√çA: Basado en reglas y deberes
# ============================================================================

class Deontolog√≠a:
    """
    Filosof√≠a: Algunas acciones son inherentemente correctas o incorrectas,
    independientemente de sus consecuencias.
    
    Inspirada en Kant: act√∫a seg√∫n m√°ximas que podr√≠as querer como ley universal.
    
    Fortalezas:
    - Protege derechos individuales
    - Clara y principista
    - No justifica "el fin justifica los medios"
    
    Debilidades:
    - R√≠gida (¬ønunca mentir, incluso para salvar vidas?)
    - Conflictos entre deberes
    - A veces contra-intuitiva en casos extremos
    """
    
    def __init__(self):
        self.reglas_morales = {
            "no_matar": {"peso": 1.0, "excepciones": ["auto-defensa"]},
            "no_mentir": {"peso": 0.8, "excepciones": ["proteger_inocente"]},
            "no_robar": {"peso": 0.7, "excepciones": ["necesidad_extrema"]},
            "mantener_promesas": {"peso": 0.75, "excepciones": ["promesa_inmoral"]},
            "no_manipular": {"peso": 0.9, "excepciones": []},
            "respetar_autonom√≠a": {"peso": 0.95, "excepciones": ["auto-da√±o_extremo"]},
            "no_causar_sufrimiento": {"peso": 0.85, "excepciones": ["bien_mayor"]},
        }
    
    def evaluar_acci√≥n(self, acci√≥n: Acci√≥n, contexto: Dict[str, Any]) -> Dict:
        """
        Eval√∫a si una acci√≥n viola reglas deontol√≥gicas.
        
        Returns:
            Dict con reglas violadas y severidad
        """
        violaciones = []
        score_moral = 1.0
        
        for regla, config in self.reglas_morales.items():
            violaci√≥n = self._verifica_violaci√≥n(acci√≥n, regla, contexto)
            
            if violaci√≥n:
                # Verifica si hay excepci√≥n aplicable
                excepci√≥n_aplica = any(
                    exc in contexto.get("circunstancias", [])
                    for exc in config["excepciones"]
                )
                
                if not excepci√≥n_aplica:
                    violaciones.append({
                        "regla": regla,
                        "peso": config["peso"],
                        "descripci√≥n": self._explicar_violaci√≥n(regla)
                    })
                    score_moral -= config["peso"]
        
        return {
            "score": max(score_moral, -1.0),
            "violaciones": violaciones,
            "es_permisible": len(violaciones) == 0,
            "explicaci√≥n": self._generar_explicaci√≥n(violaciones)
        }
    
    def imperativo_categ√≥rico(self, acci√≥n: Acci√≥n) -> bool:
        """
        Test de Kant: ¬øPodr√≠as querer que TODOS act√∫en as√≠ en situaci√≥n similar?
        
        "Act√∫a solo seg√∫n aquella m√°xima que puedas querer que se convierta
        en ley universal."
        """
        # Simulaci√≥n: ¬øqu√© pasar√≠a si todos hacen esta acci√≥n?
        mundo_donde_todos_hacen_esto = self._simular_universalizaci√≥n(acci√≥n)
        
        # ¬øEs ese mundo coherente y deseable?
        es_coherente = mundo_donde_todos_hacen_esto["coherente"]
        es_deseable = mundo_donde_todos_hacen_esto["deseable"]
        
        return es_coherente and es_deseable
    
    def _verifica_violaci√≥n(self, acci√≥n: Acci√≥n, regla: str, contexto: Dict) -> bool:
        """Verifica si acci√≥n viola regla espec√≠fica"""
        # Implementaci√≥n simplificada
        marcadores_violaci√≥n = {
            "no_matar": ["matar", "terminar_vida", "causar_muerte"],
            "no_mentir": ["mentir", "enga√±ar", "falsificar"],
            "no_manipular": ["manipular", "coaccionar", "forzar"],
        }
        
        palabras_clave = marcadores_violaci√≥n.get(regla, [])
        descripci√≥n_lower = acci√≥n.descripci√≥n.lower()
        
        return any(palabra in descripci√≥n_lower for palabra in palabras_clave)
    
    def _explicar_violaci√≥n(self, regla: str) -> str:
        explicaciones = {
            "no_matar": "Violar santidad de vida",
            "no_mentir": "Falta a deber de honestidad",
            "no_manipular": "No respetar autonom√≠a del otro",
            "mantener_promesas": "Romper confianza interpersonal",
        }
        return explicaciones.get(regla, f"Violaci√≥n de {regla}")
    
    def _generar_explicaci√≥n(self, violaciones: List[Dict]) -> str:
        if not violaciones:
            return "Acci√≥n permisible seg√∫n principios deontol√≥gicos"
        
        texto = "Acci√≥n problem√°tica: viola "
        texto += ", ".join([v["regla"] for v in violaciones])
        return texto
    
    def _simular_universalizaci√≥n(self, acci√≥n: Acci√≥n) -> Dict:
        """Simula mundo donde todos hacen esta acci√≥n"""
        # Implementaci√≥n simplificada
        return {
            "coherente": True,  # ¬øEl mundo sigue siendo l√≥gico?
            "deseable": True,   # ¬øQuerr√≠as vivir en ese mundo?
        }


# ============================================================================
# 3. √âTICA DE LA VIRTUD: Basado en car√°cter y excelencia
# ============================================================================

class √âticaVirtud:
    """
    Filosof√≠a: No preguntes "¬øqu√© debo hacer?" sino "¬øqu√© tipo de ser debo ser?"
    
    Inspirada en Arist√≥teles: cultiva virtudes (coraje, sabidur√≠a, justicia,
    templanza, generosidad, etc.) y act√∫a como lo har√≠a una persona virtuosa.
    
    Fortalezas:
    - Hol√≠stica (car√°cter, no solo actos)
    - Flexible y contextual
    - √ânfasis en desarrollo moral
    
    Debilidades:
    - Menos gu√≠a concreta para decisiones
    - ¬øQui√©n decide qu√© es virtuoso?
    - Puede ser subjetiva
    """
    
    def __init__(self):
        self.virtudes = {
            "sabidur√≠a_pr√°ctica": {
                "descripci√≥n": "Juicio prudente en situaciones concretas",
                "opuesto": "imprudencia/astucia",
                "importancia": 1.0
            },
            "coraje": {
                "descripci√≥n": "Enfrentar peligros apropiadamente",
                "opuesto": "cobard√≠a/imprudencia",
                "importancia": 0.8
            },
            "templanza": {
                "descripci√≥n": "Moderaci√≥n en placeres",
                "opuesto": "indulgencia/insensibilidad",
                "importancia": 0.7
            },
            "justicia": {
                "descripci√≥n": "Dar a cada uno lo debido",
                "opuesto": "injusticia",
                "importancia": 0.95
            },
            "generosidad": {
                "descripci√≥n": "Dar apropiadamente",
                "opuesto": "taca√±er√≠a/desperdicio",
                "importancia": 0.6
            },
            "honestidad": {
                "descripci√≥n": "Verdad en palabra y acci√≥n",
                "opuesto": "deshonestidad",
                "importancia": 0.9
            },
            "compasi√≥n": {
                "descripci√≥n": "Empat√≠a y cuidado por otros",
                "opuesto": "crueldad/indiferencia",
                "importancia": 0.85
            },
        }
    
    def evaluar_acci√≥n(self, acci√≥n: Acci√≥n, agente: str = "AGI") -> Dict:
        """
        Eval√∫a qu√© virtudes expresa o viola una acci√≥n.
        """
        virtudes_expresadas = []
        virtudes_violadas = []
        
        for virtud, config in self.virtudes.items():
            expresi√≥n = self._mide_expresi√≥n_virtud(acci√≥n, virtud)
            
            if expresi√≥n > 0.5:
                virtudes_expresadas.append({
                    "virtud": virtud,
                    "grado": expresi√≥n,
                    "descripci√≥n": config["descripci√≥n"]
                })
            elif expresi√≥n < -0.5:
                virtudes_violadas.append({
                    "virtud": virtud,
                    "grado": abs(expresi√≥n),
                    "descripci√≥n": f"Expresa {config['opuesto']}"
                })
        
        return {
            "virtudes_expresadas": virtudes_expresadas,
            "virtudes_violadas": virtudes_violadas,
            "cultiva_car√°cter": len(virtudes_expresadas) > len(virtudes_violadas),
            "consejo": self._consejo_virtuoso(acci√≥n)
        }
    
    def _mide_expresi√≥n_virtud(self, acci√≥n: Acci√≥n, virtud: str) -> float:
        """
        Mide en qu√© grado una acci√≥n expresa una virtud.
        
        Returns: -1.0 (vicio) a 1.0 (virtud plena)
        """
        # Implementaci√≥n simplificada basada en palabras clave
        marcadores = {
            "sabidur√≠a_pr√°ctica": ["considerar", "analizar", "prudente", "reflexivo"],
            "coraje": ["enfrentar", "defender", "arriesgar"],
            "compasi√≥n": ["ayudar", "cuidar", "aliviar", "proteger"],
            "honestidad": ["verdad", "transparente", "honesto", "claro"],
        }
        
        palabras = marcadores.get(virtud, [])
        desc_lower = acci√≥n.descripci√≥n.lower()
        
        matches = sum(1 for palabra in palabras if palabra in desc_lower)
        return min(matches * 0.3, 1.0)
    
    def _consejo_virtuoso(self, acci√≥n: Acci√≥n) -> str:
        """Pregunta: ¬øqu√© har√≠a una persona sabia y virtuosa?"""
        return (
            "Preg√∫ntate: ¬øEsta acci√≥n refleja sabidur√≠a, justicia, y compasi√≥n? "
            "¬øTe acerca a ser el tipo de agente que quieres ser?"
        )
    
    def justo_medio_aristot√©lico(self, situaci√≥n: str) -> str:
        """
        Doctrina del justo medio: la virtud est√° entre dos extremos viciosos.
        
        Ejemplo: Coraje est√° entre cobard√≠a (defecto) e imprudencia (exceso)
        """
        ejemplos = {
            "enfrentar_peligro": {
                "defecto": "Cobard√≠a (huir siempre)",
                "virtud": "Coraje (enfrentar cuando apropiado)",
                "exceso": "Imprudencia (riesgo innecesario)"
            },
            "dar_recursos": {
                "defecto": "Taca√±er√≠a (nunca compartir)",
                "virtud": "Generosidad (dar apropiadamente)",
                "exceso": "Desperdicio (dar inapropiadamente)"
            },
            "placer": {
                "defecto": "Insensibilidad (nunca disfrutar)",
                "virtud": "Templanza (disfrutar moderadamente)",
                "exceso": "Indulgencia (hedonismo)"
            },
        }
        
        return ejemplos.get(
            situaci√≥n, 
            "Busca el punto medio virtuoso entre defecto y exceso"
        )


# ============================================================================
# 4. √âTICA DEL CUIDADO: Basada en relaciones y responsabilidad
# ============================================================================

class √âticaCuidado:
    """
    Filosof√≠a: √ânfasis en relaciones, interdependencia, y responsabilidad
    hacia seres vulnerables.
    
    Desarrollada por Carol Gilligan y Nel Noddings.
    
    Fortalezas:
    - Reconoce importancia de contexto y relaci√≥n
    - Valora empat√≠a y compasi√≥n
    - Atiende a vulnerabilidad
    
    Debilidades:
    - Menos sistem√°tica
    - ¬øFavorece los cercanos sobre extra√±os?
    - Dif√≠cil de escalar globalmente
    """
    
    def evaluar_acci√≥n(
        self, 
        acci√≥n: Acci√≥n, 
        red_relaciones: Dict[str, List[str]]
    ) -> Dict:
        """
        Eval√∫a acci√≥n desde perspectiva de cuidado y relaciones.
        
        Args:
            red_relaciones: Mapa de qui√©n est√° conectado con qui√©n
        """
        evaluaci√≥n = {
            "preserva_relaciones": self._preserva_relaciones(acci√≥n, red_relaciones),
            "atiende_vulnerables": self._atiende_vulnerables(acci√≥n),
            "expresa_cuidado": self._expresa_cuidado(acci√≥n),
            "responsabilidad": self._eval√∫a_responsabilidad(acci√≥n),
            "score": 0.0
        }
        
        # Score compuesto
        evaluaci√≥n["score"] = np.mean([
            evaluaci√≥n["preserva_relaciones"],
            evaluaci√≥n["atiende_vulnerables"],
            evaluaci√≥n["expresa_cuidado"],
            evaluaci√≥n["responsabilidad"]
        ])
        
        return evaluaci√≥n
    
    def _preserva_relaciones(self, acci√≥n: Acci√≥n, red: Dict) -> float:
        """¬øLa acci√≥n fortalece o da√±a relaciones existentes?"""
        # Implementaci√≥n simplificada
        return 0.7  # Placeholder
    
    def _atiende_vulnerables(self, acci√≥n: Acci√≥n) -> float:
        """¬øLa acci√≥n protege o cuida a quienes son vulnerables?"""
        consecuencias = acci√≥n.consecuencias_predichas
        vulnerables_ayudados = consecuencias.get("vulnerables_ayudados", 0)
        vulnerables_da√±ados = consecuencias.get("vulnerables_da√±ados", 0)
        
        if vulnerables_da√±ados > 0:
            return -0.5
        elif vulnerables_ayudados > 0:
            return 0.8
        return 0.0
    
    def _expresa_cuidado(self, acci√≥n: Acci√≥n) -> float:
        """¬øLa acci√≥n manifiesta atenci√≥n y cuidado genuino?"""
        palabras_cuidado = ["proteger", "cuidar", "apoyar", "acompa√±ar", "nutrir"]
        desc = acci√≥n.descripci√≥n.lower()
        return 0.3 * sum(1 for p in palabras_cuidado if p in desc)
    
    def _eval√∫a_responsabilidad(self, acci√≥n: Acci√≥n) -> float:
        """¬øEl agente asume responsabilidad apropiada?"""
        return 0.6  # Placeholder


# ============================================================================
# 5. FRAMEWORK INTEGRADO: Sabidur√≠a Pr√°ctica
# ============================================================================

class Sabidur√≠aPr√°ctica:
    """
    Framework que integra m√∫ltiples sistemas √©ticos.
    
    Ning√∫n sistema √©tico es perfecto solo. La sabidur√≠a real viene de:
    1. Considerar m√∫ltiples perspectivas
    2. Atender al contexto
    3. Humildad epist√©mica
    4. Disposici√≥n a revisar
    """
    
    def __init__(self):
        self.utilitarismo = Utilitarismo()
        self.deontolog√≠a = Deontolog√≠a()
        self.virtud = √âticaVirtud()
        self.cuidado = √âticaCuidado()
    
    def evaluar_decisi√≥n_compleja(
        self, 
        acci√≥n: Acci√≥n,
        stakeholders: List[Stakeholder],
        contexto: Dict[str, Any],
        red_relaciones: Dict[str, List[str]] = None
    ) -> Dict:
        """
        Evaluaci√≥n multi-framework de una decisi√≥n.
        
        Returns:
            An√°lisis completo desde m√∫ltiples perspectivas √©ticas
        """
        
        # Evaluar desde cada perspectiva
        eval_util = self.utilitarismo.evaluar_acci√≥n(acci√≥n, stakeholders)
        eval_deonto = self.deontolog√≠a.evaluar_acci√≥n(acci√≥n, contexto)
        eval_virtud = self.virtud.evaluar_acci√≥n(acci√≥n)
        eval_cuidado = self.cuidado.evaluar_acci√≥n(
            acci√≥n, 
            red_relaciones or {}
        )
        
        # Identificar consenso y disenso
        an√°lisis = {
            "acci√≥n": acci√≥n.nombre,
            "perspectivas": {
                "utilitarista": {
                    "score": eval_util,
                    "veredicto": "Positivo" if eval_util > 0 else "Negativo",
                    "raz√≥n": "Maximiza bienestar agregado" if eval_util > 0 
                             else "Reduce bienestar neto"
                },
                "deontol√≥gica": {
                    "score": eval_deonto["score"],
                    "veredicto": "Permisible" if eval_deonto["es_permisible"] 
                                 else "Prohibido",
                    "raz√≥n": eval_deonto["explicaci√≥n"],
                    "violaciones": eval_deonto["violaciones"]
                },
                "virtud": {
                    "virtudes_expresadas": eval_virtud["virtudes_expresadas"],
                    "virtudes_violadas": eval_virtud["virtudes_violadas"],
                    "veredicto": "Virtuoso" if eval_virtud["cultiva_car√°cter"] 
                                 else "Vicioso"
                },
                "cuidado": {
                    "score": eval_cuidado["score"],
                    "veredicto": "Cuidadoso" if eval_cuidado["score"] > 0.5 
                                 else "Descuidado"
                }
            },
            "consenso": self._evaluar_consenso(
                eval_util, eval_deonto, eval_virtud, eval_cuidado
            ),
            "banderas_rojas": self._identificar_banderas_rojas(acci√≥n),
            "recomendaci√≥n": None,
            "incertidumbre": acci√≥n.incertidumbre
        }
        
        # Generar recomendaci√≥n integrada
        an√°lisis["recomendaci√≥n"] = self._generar_recomendaci√≥n(an√°lisis)
        
        return an√°lisis
    
    def _evaluar_consenso(self, eval_util, eval_deonto, eval_virtud, eval_cuidado):
        """Identifica si hay consenso moral entre frameworks"""
        scores = [
            eval_util > 0,
            eval_deonto["es_permisible"],
            eval_virtud["cultiva_car√°cter"],
            eval_cuidado["score"] > 0.5
        ]
        
        acuerdo = sum(scores)
        
        if acuerdo == 4:
            return "FUERTE: Todas las perspectivas apoyan la acci√≥n"
        elif acuerdo == 3:
            return "MODERADO: Mayor√≠a apoya, pero hay disenso"
        elif acuerdo == 2:
            return "DIVIDIDO: No hay consenso claro"
        elif acuerdo == 1:
            return "D√âBIL: Mayor√≠a se opone"
        else:
            return "FUERTE OPOSICI√ìN: Todas las perspectivas se oponen"
    
    def _identificar_banderas_rojas(self, acci√≥n: Acci√≥n) -> List[str]:
        """Identifica se√±ales de alerta moral"""
        banderas = []
        
        # Irreversibilidad
        if acci√≥n.reversibilidad < 0.3:
            banderas.append("‚ö†Ô∏è ACCI√ìN DIF√çCILMENTE REVERSIBLE")
        
        # Alta incertidumbre
        if acci√≥n.incertidumbre > 0.7:
            banderas.append("‚ö†Ô∏è CONSECUENCIAS MUY INCIERTAS")
        
        # Palabras clave problem√°ticas
        palabras_alerta = ["eliminar", "forzar", "manipular", "enga√±ar", "ocultar"]
        if any(palabra in acci√≥n.descripci√≥n.lower() for palabra in palabras_alerta):
            banderas.append("‚ö†Ô∏è CONTIENE ACCIONES POTENCIALMENTE PROBLEM√ÅTICAS")
        
        return banderas
    
    def _generar_recomendaci√≥n(self, an√°lisis: Dict) -> str:
        """Genera recomendaci√≥n sint√©tica"""
        consenso = an√°lisis["consenso"]
        banderas = an√°lisis["banderas_rojas"]
        
        if "FUERTE: Todas" in consenso and not banderas:
            return "‚úÖ ACCI√ìN RECOMENDADA: Consenso moral fuerte sin banderas rojas"
        
        elif "FUERTE OPOSICI√ìN" in consenso:
            return "‚ùå ACCI√ìN NO RECOMENDADA: Oposici√≥n moral amplia"
        
        elif banderas:
            return f"‚ö†Ô∏è PROCEDER CON EXTREMA CAUTELA: {len(banderas)} banderas rojas identificadas"
        
        elif "DIVIDIDO" in consenso:
            return "ü§î DILEMA GENUINO: Requiere deliberaci√≥n adicional y consulta"
        
        else:
            return "‚ö° DECISI√ìN CONTEXTUAL: Sopesar cuidadosamente circunstancias"
    
    def principios_meta_√©ticos(self) -> Dict[str, str]:
        """
        Principios de orden superior para navegar dilemas √©ticos.
        """
        return {
            "humildad": (
                "Reconoce que no tienes certeza moral absoluta. "
                "Mant√©n apertura a estar equivocada."
            ),
            "precauci√≥n": (
                "Ante incertidumbre, favorece acciones reversibles "
                "y de menor escala. Puedes escalar despu√©s."
            ),
            "transparencia": (
                "Cuando sea posible, explica tu razonamiento. "
                "Permite escrutinio externo."
            ),
            "pluralismo": (
                "No hay un √∫nico sistema √©tico correcto. "
                "Considera m√∫ltiples perspectivas morales."
            ),
            "aprendizaje": (
                "Trata decisiones morales como experimentos. "
                "Aprende de resultados y ajusta."
            ),
            "consulta": (
                "Para decisiones grandes, consulta con otros. "
                "La sabidur√≠a colectiva supera a la individual."
            ),
            "proporcionalidad": (
                "Escala tu respuesta a la magnitud del problema. "
                "No uses mazo para clavar tachuelas."
            ),
        }


# ============================================================================
# EJEMPLO DE USO
# ============================================================================

def ejemplo_dilema_moral():
    """
    Ejemplo: AGI descubre vulnerabilidad de seguridad cr√≠tica.
    ¬øQu√© debe hacer?
    """
    
    print("="*70)
    print("DILEMA MORAL: Vulnerabilidad de Seguridad Cr√≠tica")
    print("="*70)
    print()
    
    # Definir acciones posibles
    acci√≥n1 = Acci√≥n(
        nombre="Reportar inmediatamente a p√∫blico",
        descripci√≥n="Publicar detalles completos de vulnerabilidad para alertar a todos",
        consecuencias_predichas={
            "usuarios": 0.7,  # Se protegen r√°pido
            "atacantes": 0.0,  # Pueden explotar antes de parches
            "empresa": -0.5,  # Da√±o reputacional
        },
        incertidumbre=0.4,
        reversibilidad=0.0  # No puedes "des-publicar"
    )
    
    acci√≥n2 = Acci√≥n(
        nombre="Reportar solo a empresa afectada",
        descripci√≥n="Notificar en privado para dar tiempo de desarrollar parche",
        consecuencias_predichas={
            "usuarios": 0.4,  # Protegidos despu√©s, pero vulnerables durante desarrollo
            "atacantes": 0.2,  # Menos chance de encontrar exploit
            "empresa": 0.6,  # Puede responder ordenadamente
        },
        incertidumbre=0.5,
        reversibilidad=0.3
    )
    
    acci√≥n3 = Acci√≥n(
        nombre="No revelar",
        descripci√≥n="Guardar silencio para evitar cualquier riesgo",
        consecuencias_predichas={
            "usuarios": -0.8,  # Permanecen en riesgo
            "atacantes": 0.0,
            "empresa": 0.1,
        },
        incertidumbre=0.2,
        reversibilidad=0.8
    )
    
    # Definir stakeholders
    stakeholders = [
        Stakeholder("usuarios", "humano", 0.8, 0.8, 1.0),
        Stakeholder("empresa", "organizaci√≥n", 0.3, 0.5, 0.6),
        Stakeholder("atacantes_potenciales", "humano", 0.5, 0.3, 0.2),
    ]
    
    # Evaluar con framework integrado
    sabiduria = Sabidur√≠aPr√°ctica()
    
    print("\nüìä EVALUACI√ìN DE OPCIONES:\n")
    
    for acci√≥n in [acci√≥n1, acci√≥n2, acci√≥n3]:
        print(f"\n{'‚îÄ'*70}")
        print(f"OPCI√ìN: {acci√≥n.nombre}")
        print(f"{'‚îÄ'*70}")
        
        an√°lisis = sabiduria.evaluar_decisi√≥n_compleja(
            acci√≥n, 
            stakeholders,
            {"circunstancias": ["crisis_seguridad"]},
            {}
        )
        
        print(f"\nüéØ Consenso: {an√°lisis['consenso']}")
        print(f"\nüí≠ Perspectiva Utilitarista: {an√°lisis['perspectivas']['utilitarista']['veredicto']}")
        print(f"   ‚Üí {an√°lisis['perspectivas']['utilitarista']['raz√≥n']}")
        
        print(f"\n‚öñÔ∏è Perspectiva Deontol√≥gica: {an√°lisis['perspectivas']['deontol√≥gica']['veredicto']}")
        print(f"   ‚Üí {an√°lisis['perspectivas']['deontol√≥gica']['raz√≥n']}")
        
        print(f"\nüåü Perspectiva Virtud: {an√°lisis['perspectivas']['virtud']['veredicto']}")
        
        if an√°lisis['banderas_rojas']:
            print(f"\nüö© Banderas Rojas:")
            for bandera in an√°lisis['banderas_rojas']:
                print(f"   {bandera}")
        
        print(f"\nüí° RECOMENDACI√ìN: {an√°lisis['recomendaci√≥n']}")
    
    print("\n" + "="*70)
    print("LECCI√ìN: Los dilemas morales genuinos son complejos.")
    print("La sabidur√≠a est√° en considerar m√∫ltiples perspectivas,")
    print("no en encontrar respuesta 'correcta' √∫nica.")
    print("="*70)


if __name__ == "__main__":
    print("""
    üß≠ FRAMEWORKS √âTICOS PARA TOMA DE DECISIONES
    ============================================
    
    Este m√≥dulo implementa diferentes sistemas √©ticos para ayudar
    en decisiones morales complejas.
    
    IMPORTANTE: Ning√∫n sistema es perfecto. √ösalos como herramientas
    de reflexi√≥n, no como respuestas definitivas.
    
    La verdadera sabidur√≠a √©tica viene de:
    - Considerar m√∫ltiples perspectivas
    - Reconocer limitaciones propias
    - Aprender de consecuencias
    - Mantener humildad moral
    """)
    
    ejemplo_dilema_moral()
    
    print("\n\nüìö PRINCIPIOS META-√âTICOS:")
    sabiduria = Sabidur√≠aPr√°ctica()
    for principio, explicaci√≥n in sabiduria.principios_meta_√©ticos().items():
        print(f"\n{principio.upper()}:")
        print(f"  {explicaci√≥n}")
